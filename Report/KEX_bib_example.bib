% -- This file contains the entries on the references used in your text --
% Search your references on the web and copy & paste them here 
% OR generate them manually following the logical structure of BibTex references 

	% <----- entry "name" or "tag", which is needed to reference the entry in the main text 
	
	% followed by a list of field for the specific information on the item
	
@ARTICLE{ alfven1942		,
   author = {{Alfv{\'e}n}, H.},		
    title = "{Existence of Electromagnetic-Hydrodynamic Waves}",
  journal = {Nature},
     year = 1942,
    month = oct,
   volume = 150,
    pages = {405-406},
      doi = {10.1038/150405d0}
}

@electronic{website123,
 url = "https://deepmind.com/blog/alphago-zero-learning-scratch/",
 year = 2017,
 month = oct,
 title = {AlphaGo Zero: Learning from scratch},
 address = "{DeepMind, London, UK}",
}

@article{silver,
	Author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	Date = {2017/10/18/online},
	Date-Added = {2018-02-23 08:29:16 +0000},
	Date-Modified = {2018-02-23 08:29:16 +0000},
	Day = {18},
	Journal = {Nature},
	L3 = {10.1038/nature24270; https://www.nature.com/articles/nature24270#supplementary-information},
	M3 = {Article},
	Month = {10},
	Pages = {354 EP  -},
	Publisher = {Macmillan Publishers Limited, part of Springer Nature. All rights reserved. SN  -},
	Title = {Mastering the game of Go without human knowledge},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nature24270},
	Volume = {550},
	Year = {2017},
	Bdsk-Url-1 = {http://dx.doi.org/10.1038/nature24270}
}
@book{Sutton:1998:IRL:551283,
	author = {Sutton, Richard S. and Barto, Andrew G.},
	title = {Introduction to Reinforcement Learning},
	year = {1998},
	isbn = {0262193981},
	edition = {1st},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
}

@InProceedings{BP,
author="Li, Jing
and Cheng, Ji-hang
and Shi, Jing-yuan
and Huang, Fei",
editor="Jin, David
and Lin, Sally",
title="Brief Introduction of Back Propagation (BP) Neural Network Algorithm and Its Improvement",
booktitle="Advances in Computer Science and Information Engineering",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="553--558",
abstract="The back propagation (BP) neural network algorithm is a multi-layer feedforward network trained according to error back propagation algorithm and is one of the most widely applied neural network models. BP network can be used to learn and store a great deal of mapping relations of input-output model, and no need to disclose in advance the mathematical equation that describes these mapping relations. Its learning rule is to adopt the steepest descent method in which the back propagation is used to regulate the weight value and threshold value of the network to achieve the minimum error sum of square. This paper focuses on the analysis of the characteristics and mathematical theory of BP neural network and also points out the shortcomings of BP algorithm as well as several methods for improvement.",
isbn="978-3-642-30223-7"
}

@article{epsilon,
  author    = {Volodymyr Kuleshov and
               Doina Precup},
  title     = {Algorithms for multi-armed bandit problems},
  journal   = {CoRR},
  volume    = {abs/1402.6028},
  year      = {2014},
  url       = {http://arxiv.org/abs/1402.6028},
  archivePrefix = {arXiv},
  eprint    = {1402.6028},
  timestamp = {Wed, 07 Jun 2017 14:41:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KuleshovP14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Reward,
title={Reward Design in Cooperative Multi-agent Reinforcement Learning for Packet Routing},
author={Hangyu Mao and Zhibo Gong and Zhen Xiao},
year={2018},
url={https://openreview.net/forum?id=r15kjpHa-},
}

@article{Qlearn,
  author    = {Todd Hester and
               Matej Vecerik and
               Olivier Pietquin and
               Marc Lanctot and
               Tom Schaul and
               Bilal Piot and
               Andrew Sendonaris and
               Gabriel Dulac{-}Arnold and
               Ian Osband and
               John Agapiou and
               Joel Z. Leibo and
               Audrunas Gruslys},
  title     = {Learning from Demonstrations for Real World Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1704.03732},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.03732},
  archivePrefix = {arXiv},
  eprint    = {1704.03732},
  timestamp = {Wed, 07 Jun 2017 14:41:33 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HesterVPLSPSDOA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@incollection{Conv,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}
@inproceedings{Opt_neurons,
    author = {Liu, Yinyin and Starzyk, Janusz A. and Zhu, Zhen},
    title = {Optimizing Number of Hidden Neurons in Neural Networks},
    booktitle = {Proceedings of the 25th Conference on Proceedings of the 25th IASTED International Multi-Conference: Artificial Intelligence and Applications},
    series = {AIAP'07},
    year = {2007},
    location = {Innsbruck, Austria},
    pages = {121--126},
    numpages = {6},
    url = {http://dl.acm.org/citation.cfm?id=1295303.1295324},
    acmid = {1295324},
    publisher = {ACTA Press},
    address = {Anaheim, CA, USA},
    keywords = {function approximation, network optimization, neural network, overfitting, signal-to-noise ratio figure},
}
@electronic{code,
 url = "https://github.com/rlcode/reinforcement-learning",
 year = 2018,
 month = apr,
 title = {Reinforcement Learning GitHub},
}